{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from PIL import Image\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from environments import Snake\n",
    "from methods import ActorCriticNetwork, ReplayMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = np.array([4, 1, 6, 7, 9], dtype=np.float32)\n",
    "V = np.array([-1, -2, 1, 4, -5], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift_vector(vec, pos=1):\n",
    "    vec_ = np.concatenate((vec, np.zeros(pos)))\n",
    "    return vec_[pos:]\n",
    "\n",
    "def calc_targets(rewards, values, depth, gamma):\n",
    "    r = np.array(rewards, dtype=np.float32).ravel()\n",
    "    v = np.array(values, dtype=np.float32).ravel()\n",
    "    targets = np.zeros_like(r)\n",
    "    for i in range(depth):\n",
    "        targets += (gamma ** i) * shift_vector(r, i)\n",
    "    targets += (gamma ** depth) * shift_vector(v, depth)\n",
    "    return targets.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snake class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNWbgUmMGLjVm4FJjBi419m+DkmMHVTeDfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ea856d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = Snake()\n",
    "img = s.reset()\n",
    "s.plot_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXGrMwKXGDFxqzMClxgxcaszApcb+DYIhZQmULNETAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11eb59320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, r, done = s.step(2)\n",
    "s.plot_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SnakeAgent:\n",
    "    \n",
    "    def __init__(self, model_name=\"baseline_agent\"):\n",
    "        \n",
    "        \"\"\"Class for training and evaluating DQN agent on Atari games\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        game_id: str\n",
    "            game identifier in gym environment, e.g. \"Pong\"\n",
    "        num_actions: int\n",
    "            number of actions the agent can take\n",
    "        model_name: str\n",
    "            name of the model\n",
    "        \"\"\"\n",
    "        \n",
    "        ############################ Game environment ############################\n",
    "        \n",
    "        self.train_env = Snake()\n",
    "        self.num_actions = 4\n",
    "            \n",
    "        self.path = \"snake_models\" + \"/\" + model_name\n",
    "        if not os.path.exists(self.path):\n",
    "            os.makedirs(self.path)\n",
    "        \n",
    "        ############################# Agent & Target #############################\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self.agent_net = ActorCriticNetwork(self.num_actions, scope=\"agent\")\n",
    "        self.target_net = ActorCriticNetwork(self.num_actions, scope=\"target\")\n",
    "        \n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        all_vars = tf.trainable_variables()\n",
    "        num_vars = len(all_vars) // 2\n",
    "        self.agent_vars = all_vars[:num_vars]\n",
    "        self.target_vars = all_vars[num_vars:]\n",
    "        \n",
    "    def set_parameters(self, \n",
    "                       replay_memory_size=50000,\n",
    "                       replay_start_size=10000,\n",
    "                       init_eps=1,\n",
    "                       final_eps=0.1,\n",
    "                       annealing_steps=100000,\n",
    "                       discount_factor=0.99,\n",
    "                       n_step=3,\n",
    "                       max_episode_length=2000):\n",
    "        \n",
    "        # create experience replay and fill it with random policy samples\n",
    "        self.rep_buffer = ReplayMemory(replay_memory_size)\n",
    "        frame_count = 0\n",
    "        while (frame_count < replay_start_size):\n",
    "            s = self.train_env.reset()\n",
    "            for time_step in range(max_episode_length):\n",
    "                a = np.random.randint(self.num_actions)\n",
    "                s_, r, end = self.train_env.step(a)\n",
    "                self.rep_buffer.push(s, a, np.sign(r), s_, end)\n",
    "                s = s_\n",
    "                frame_count += 1\n",
    "                if end:\n",
    "                    break\n",
    "                        \n",
    "        self.eps = init_eps\n",
    "        self.final_eps = final_eps\n",
    "        self.eps_drop = (init_eps - final_eps) / annealing_steps\n",
    "        self.gamma = discount_factor\n",
    "        self.max_ep_length = max_episode_length\n",
    "        self.n_step = n_step\n",
    "        \n",
    "    def train(self,\n",
    "              gpu_id=0,\n",
    "              batch_size=32,\n",
    "              agent_update_freq=4,\n",
    "              target_update_freq=5000,\n",
    "              tau=1,\n",
    "              max_num_episodes=100000,\n",
    "              max_num_epochs=50000,\n",
    "              performance_print_freq=100,\n",
    "              save_freq=10000):\n",
    "        \n",
    "        target_ops = self.update_target_graph(tau)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(self.init)\n",
    "            \n",
    "            train_rewards = []\n",
    "            PG_loss, VAL_loss = [], []\n",
    "            frame_count = 0\n",
    "            episode_count = 0\n",
    "            num_epochs = 0\n",
    "            \n",
    "            while num_epochs < max_num_epochs:\n",
    "                \n",
    "                train_ep_reward = 0\n",
    "                \n",
    "                # reset the environment / start new game\n",
    "                s = self.train_env.reset()\n",
    "                \n",
    "                states = []\n",
    "                actions = []\n",
    "                rewards = []\n",
    "                \n",
    "                for time_step in range(self.max_ep_length):\n",
    "                    \n",
    "                    act_probs = self.agent_net.get_probs(sess, [s])\n",
    "                    a = np.random.choice(self.num_actions, p=act_probs.ravel())\n",
    "                    states.append(s)\n",
    "                    actions.append(a)\n",
    "                    # make step in the environment\n",
    "                    s, r, end = self.train_env.step(a)\n",
    "                    rewards.append(r)\n",
    "\n",
    "                    # update current state and statistics\n",
    "                    frame_count += 1\n",
    "                    train_ep_reward += r\n",
    "                    \n",
    "                    # make checkpoints of network weights and save learning curve\n",
    "                    if frame_count % save_freq == 1:\n",
    "                        num_epochs += 1\n",
    "                        try:\n",
    "                            self.saver.save(sess, self.path+\"/model\", global_step=num_epochs)\n",
    "                            np.savez(self.path+\"/learning_curve.npz\", r=train_rewards)\n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                    if end: break\n",
    "                \n",
    "                values = self.agent_net.get_values(sess, states)\n",
    "                targets = calc_targets(rewards, values, self.n_step, self.gamma)\n",
    "                pg_targets = targets - values\n",
    "                  \n",
    "                # update network weights\n",
    "                \n",
    "                pg_loss, val_loss = self.agent_net.update(sess, states, actions, pg_targets, targets)\n",
    "                PG_loss.append(pg_loss)\n",
    "                VAL_loss.append(val_loss)\n",
    "                         \n",
    "                episode_count += 1\n",
    "                train_rewards.append(train_ep_reward)\n",
    "                \n",
    "                # print performance once in a while\n",
    "                if episode_count % performance_print_freq == 0:\n",
    "                    avg_reward = np.mean(train_rewards[-performance_print_freq:])\n",
    "                    avg_pg_loss = np.mean(PG_loss[-performance_print_freq:])\n",
    "                    avg_val_loss = np.mean(VAL_loss[-performance_print_freq:])\n",
    "                    print(\"Train info:\", frame_count, avg_reward, avg_pg_loss, avg_val_loss)  \n",
    "\n",
    "    def update_target_graph(self, tau):\n",
    "        op_holder = []\n",
    "        for agnt, trgt in zip(self.agent_vars, self.target_vars):\n",
    "            op = trgt.assign(agnt.value()*tau + (1 - tau)*trgt.value())\n",
    "            op_holder.append(op)\n",
    "        return op_holder\n",
    "\n",
    "    def update_target_weights(self, sess, op_holder):\n",
    "        for op in op_holder:\n",
    "            sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = SnakeAgent(model_name=\"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa.set_parameters(max_episode_length=1000, replay_memory_size=50000, replay_start_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train info: 777 -0.87 -21.4547 0.240491\n",
      "Train info: 1543 -0.92 -16.298 0.153546\n",
      "Train info: 2459 -0.87 -4.83338 0.0798858\n",
      "Train info: 3274 -0.92 -0.0808705 0.0443214\n",
      "Train info: 4101 -0.86 7.83107 0.0390468\n",
      "Train info: 4857 -0.9 4.32984 0.0273029\n",
      "Train info: 5626 -0.89 7.51827 0.028144\n",
      "Train info: 6425 -0.9 6.78224 0.0240741\n",
      "Train info: 7243 -0.88 5.03037 0.0277286\n",
      "Train info: 8133 -0.89 5.31946 0.0325434\n",
      "Train info: 8920 -0.94 0.517994 0.0202131\n",
      "Train info: 9782 -0.92 5.53896 0.0201518\n",
      "Train info: 10650 -0.82 7.96302 0.0324679\n",
      "Train info: 11531 -0.86 5.49608 0.0273787\n",
      "Train info: 12313 -0.92 4.79561 0.0148475\n",
      "Train info: 13117 -0.93 4.66935 0.0132647\n",
      "Train info: 13909 -0.91 9.58051 0.0154501\n",
      "Train info: 14734 -0.87 6.26124 0.0224615\n",
      "Train info: 15574 -0.9 4.14778 0.0195258\n",
      "Train info: 16438 -0.92 3.73967 0.0165844\n",
      "Train info: 17283 -0.89 4.78244 0.0182421\n",
      "Train info: 18106 -0.84 6.12342 0.0308484\n",
      "Train info: 18925 -0.84 6.74261 0.0261258\n",
      "Train info: 19724 -0.9 5.0197 0.0214938\n",
      "Train info: 20619 -0.92 4.01215 0.0162865\n",
      "Train info: 21377 -0.91 3.68848 0.0177206\n",
      "Train info: 22261 -0.83 7.74222 0.0269978\n",
      "Train info: 23075 -0.88 2.61304 0.0188717\n",
      "Train info: 23851 -0.88 4.09934 0.0203936\n",
      "Train info: 24714 -0.84 5.97729 0.0274202\n",
      "Train info: 25611 -0.93 3.01489 0.013868\n",
      "Train info: 26414 -0.86 5.84611 0.0234286\n",
      "Train info: 27194 -0.93 2.62259 0.0169402\n",
      "Train info: 27914 -0.9 4.61494 0.0183613\n",
      "Train info: 28733 -0.89 3.32735 0.0223697\n",
      "Train info: 29667 -0.91 3.62483 0.016219\n",
      "Train info: 30478 -0.86 4.65362 0.0285459\n",
      "Train info: 31313 -0.95 1.99205 0.0119261\n",
      "Train info: 32174 -0.81 11.5237 0.0258596\n",
      "Train info: 33025 -0.9 5.45941 0.0148073\n",
      "Train info: 33750 -0.87 2.51779 0.0241846\n",
      "Train info: 34609 -0.9 3.43003 0.0180851\n",
      "Train info: 35403 -0.92 3.58941 0.0144103\n",
      "Train info: 36317 -0.93 4.84328 0.0145991\n",
      "Train info: 37091 -0.86 5.01448 0.0257346\n",
      "Train info: 37815 -0.9 3.34497 0.0248818\n",
      "Train info: 38635 -0.86 10.9956 0.0170676\n",
      "Train info: 39418 -0.87 6.32561 0.0221187\n"
     ]
    }
   ],
   "source": [
    "aa.train(gpu_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "agent_net = PGNetwork(4, scope=\"agent\")\n",
    "saver = tf.train.Saver()\n",
    "env = Snake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS40ZuNSYgUuNGbjU2L8Az71kxnG33dgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121fd8ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACgNJREFUeJzt3f+rZHUdx/Hnq1XbNEsoC3MlhUKIII3FCkNIKazECvpB\nwaAI9qdEKQjtt/6Awn6IQDYryJKyFiLsi5RRQZq76/bFXQ1bDHetVgtRN9rNfPfDnY3Ntu65O+fc\nmfvm+YCLd+Ye5r6H5ek5c+7M+aSqkNTTixY9gKTpGLjUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFL\njZ0yxYOelhfXZs6Y4qElAX/nMEfrSFbbbpLAN3MGb8kVUzy0JOC++tGg7TxElxozcKkxA5caM3Cp\nMQOXGjNwqTEDlxozcKmxQYEnuTLJw0keSXLT1ENJGseqgSfZBHweeDfwBuDaJG+YejBJ8xuyB78E\neKSq9lfVUeAO4H3TjiVpDEMCPxd47LjbB2b3SVpyo33YJMk2YBvAZk4f62ElzWHIHvwgcN5xt7fM\n7vsPVXVrVW2tqq2n8uKx5pM0hyGB3w+8PskFSU4DrgG+M+1Yksaw6iF6VT2X5GPAD4BNwG1V9eDk\nk0ma26DX4FV1F3DXxLNIGpnvZJMaM3CpMQOXGjNwqTEDlxozcKkxA5caM3CpsUlWNpH+n7994C2L\nHmEyj1+26mpCozjymXsHbeceXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqbMjKJrclOZTk\nt+sxkKTxDNmDfxm4cuI5JE1g1cCr6qfAX9dhFkkj8zW41JhLF0mNjbYHd+kiafl4iC41NuTPZF8H\nfgFcmORAko9OP5akMQxZm+za9RhE0vg8RJcaM3CpMQOXGjNwqTEDlxozcKkxA5caM3CpMZcu0ro7\nfcd9ix5hMq/bsT6/5y91eNB27sGlxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGpsyEUX\nz0tyT5K9SR5McsN6DCZpfkPei/4c8Imq2p3kTGBXkrurau/Es0ma05C1yf5YVbtn3z8D7APOnXow\nSfNb06fJkpwPXAz818eBXLpIWj6DT7IleSnwLeDGqnr6hT936SJp+QwKPMmprMR9e1V9e9qRJI1l\nyFn0AF8E9lXVZ6cfSdJYhuzBLwU+BFyeZM/s6z0TzyVpBEPWJvs5kHWYRdLIfCeb1JiBS40ZuNSY\ngUuNGbjUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFLjQ256OLm\nJL9M8qvZ0kWfXo/BJM1vyMIHR4DLq+rZ2eWTf57ke1V178SzSZrTkIsuFvDs7Oaps6+acihJ4xi6\n8MGmJHuAQ8DdVXXCpYuS7Eyy8x8cGXtOSSdhUOBV9c+qugjYAlyS5I0n2Mali6Qls6az6FX1FHAP\ncOU040ga05Cz6GcnOWv2/UuAdwIPTT2YpPkNOYt+DvCVJJtY+R/CN6rqu9OOJWkMQ86i/5qVNcEl\nbTC+k01qzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszA\npcYMXGrMwKXGBgc+uzb6A0m8Hpu0QaxlD34DsG+qQSSNb+jKJluA9wLbpx1H0piG7sFvAT4JPD/h\nLJJGNmThg6uAQ1W1a5XtXJtMWjJD9uCXAlcneRS4A7g8yVdfuJFrk0nLZ9XAq+rmqtpSVecD1wA/\nrqrrJp9M0tz8O7jU2JC1yf6tqn4C/GSSSSSNzj241JiBS40ZuNSYgUuNGbjUmIFLjRm41JiBS40Z\nuNSYgUuNGbjUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFLjQ26ZNPsiqrPAP8EnquqrVMOJWkca7km\n2zuq6snJJpE0Og/RpcaGBl7AD5PsSrJtyoEkjWfoIfrbq+pgklcBdyd5qKp+evwGs/C3AWzm9JHH\nlHQyBu3Bq+rg7L+HgB3AJSfYxqWLpCUzZPHBM5Kceex74F3Ab6ceTNL8hhyivxrYkeTY9l+rqu9P\nOpWkUawaeFXtB960DrNIGpl/JpMaM3CpMQOXGjNwqTEDlxozcKkxA5caM3CpMQOXGjNwqTEDlxoz\ncKkxA5caM3CpMQOXGjNwqTEDlxozcKmxQYEnOSvJnUkeSrIvydumHkzS/IZeF/1zwPer6oNJTgMv\nfC5tBKsGnuTlwGXAhwGq6ihwdNqxJI1hyCH6BcATwJeSPJBk++z66JKW3JDATwHeDHyhqi4GDgM3\nvXCjJNuS7Eyy8x8cGXlMSSdjSOAHgANVdd/s9p2sBP8fXLpIWj6rBl5VfwIeS3Lh7K4rgL2TTiVp\nFEPPol8P3D47g74f+Mh0I0kay6DAq2oPsHXiWSSNzHeySY0ZuNSYgUuNGbjUmIFLjRm41JiBS40Z\nuNSYgUuNDX2r6tJ6zb1nrtvvevytz6zb75LG4B5caszApcYMXGrMwKXGDFxqzMClxgxcaszApcYM\nXGps1cCTXJhkz3FfTye5cT2GkzSfVd+qWlUPAxcBJNkEHAR2TDyXpBGs9RD9CuD3VfWHKYaRNK61\nftjkGuDrJ/pBkm3ANoDNLj4qLYXBe/DZogdXA9880c9dukhaPms5RH83sLuq/jzVMJLGtZbAr+V/\nHJ5LWk6DAp+tB/5O4NvTjiNpTEPXJjsMvGLiWSSNzHeySY0ZuNSYgUuNGbjUmIFLjRm41JiBS40Z\nuNRYqmr8B02eANb6kdJXAk+OPsxy6PrcfF6L89qqOnu1jSYJ/GQk2VlVWxc9xxS6Pjef1/LzEF1q\nzMClxpYp8FsXPcCEuj43n9eSW5rX4JLGt0x7cEkjW4rAk1yZ5OEkjyS5adHzjCHJeUnuSbI3yYNJ\nblj0TGNKsinJA0m+u+hZxpTkrCR3Jnkoyb4kb1v0TPNY+CH67Frrv2PlijEHgPuBa6tq70IHm1OS\nc4Bzqmp3kjOBXcD7N/rzOibJx4GtwMuq6qpFzzOWJF8BflZV22cXGj29qp5a9Fwnaxn24JcAj1TV\n/qo6CtwBvG/BM82tqv5YVbtn3z8D7APOXexU40iyBXgvsH3Rs4wpycuBy4AvAlTV0Y0cNyxH4OcC\njx13+wBNQjgmyfnAxcB9i51kNLcAnwSeX/QgI7sAeAL40uzlx/bZ9Qg3rGUIvLUkLwW+BdxYVU8v\nep55JbkKOFRVuxY9ywROAd4MfKGqLgYOAxv6nNAyBH4QOO+421tm9214SU5lJe7bq6rLFWkvBa5O\n8igrL6cuT/LVxY40mgPAgao6dqR1JyvBb1jLEPj9wOuTXDA7qXEN8J0FzzS3JGHltdy+qvrsoucZ\nS1XdXFVbqup8Vv6tflxV1y14rFFU1Z+Ax5JcOLvrCmBDnxRd69pko6uq55J8DPgBsAm4raoeXPBY\nY7gU+BDwmyR7Zvd9qqruWuBMWt31wO2znc1+4CMLnmcuC/8zmaTpLMMhuqSJGLjUmIFLjRm41JiB\nS40ZuNSYgUuNGbjU2L8Az71kxnG33dgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121fd8ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"snake_models/test/model-55\")\n",
    "    s = env.reset()\n",
    "    for i in range(20):\n",
    "        probs = agent_net.get_probs(sess, [s])\n",
    "        a = agent_net.get_p_argmax(sess, [s])[0]\n",
    "        s, r, done = env.step(a)\n",
    "        \n",
    "        \n",
    "        env.plot_state()\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        time.sleep(0.01)\n",
    "        \n",
    "        if done: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06805254,  0.69527936,  0.05574758,  0.18092045]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
