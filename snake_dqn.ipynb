{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from PIL import Image\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from environments import Snake\n",
    "from methods import QNetwork, ReplayMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snake class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAChpJREFUeJzt3f/LnXUdx/HnqzldLkvoqzlJwTAiKGNYYQgphZVYQT8o\nJCTBfiq0ArF+6x+I+iGCWJaQJWUNIuyLlFFBLbe5vrjNsFG4ac2I8EvkMt/9cJ/FssV93TvXdZ9z\nv3k+4GbnnPvi3O/DeO66znWfXZ9UFZJ6et6iB5A0HQOXGjNwqTEDlxozcKkxA5caM3CpMQOXGjNw\nqbEzpnjSM3NWbWHrFE8tCfgHT3G8ns5q200S+Ba28qZcNcVTSwJ21w8HbechutSYgUuNGbjUmIFL\njRm41JiBS40ZuNSYgUuNDQo8ydVJHkzyUJJbpx5K0jhWDTzJJuBzwDuB1wLXJ3nt1INJmt+QPfhl\nwENVdbiqjgN3Au+ZdixJYxgS+PnAwyfdPzJ7TNKSG+0/myTZAewA2MLZYz2tpDkM2YMfBS446f62\n2WP/paq+UFXbq2r7Zs4aaz5JcxgS+H3Aq5NclORM4Drg29OOJWkMqx6iV9UzST4MfB/YBNxWVQ9M\nPpmkuQ16D15VdwN3TzyLpJH5STapMQOXGjNwqTEDlxozcKkxA5caM3CpMQOXGjNwqTEDlxozcKkx\nA5caM3CpMQOXGjNwqTEDlxozcKkxA5caG7KyyW1JjiX57XoMJGk8Q/bgXwaunngOSRNYNfCq+gnw\n13WYRdLIfA8uNebSRVJjo+3BXbpIWj4eokuNDfk12deAnwOXJDmS5EPTjyVpDEPWJrt+PQaRND4P\n0aXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszA\npcYMXGrMwKXGhlx08YIk9yY5kOSBJDetx2CS5jdk4YNngI9X1b4k5wB7k9xTVQcmnk3SnIasTfZo\nVe2b3X4COAicP/Vgkua3pqWLklwIXArsPsX3XLpIWjKDT7IleQHwTeDmqnr8ud936SJp+QwKPMlm\nVuK+o6q+Ne1IksYy5Cx6gC8CB6vq09OPJGksQ/bglwM3AFcm2T/7etfEc0kawZC1yX4GZB1mkTQy\nP8kmNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJj\nBi41ZuBSY0MuurglyS+T/Gq2dNGn1mMwSfMbsvDB08CVVfXk7PLJP0vy3ar6xcSzSZrTkIsuFvDk\n7O7m2VdNOZSkcQxd+GBTkv3AMeCeqjrl0kVJ9iTZ80+eHntOSadhUOBV9a+qegOwDbgsyetOsY1L\nF0lLZk1n0avqb8C9wNXTjCNpTEPOor80ybmz288H3g4cmnowSfMbchb9POD2JJtY+Qfh61X1nWnH\nkjSGIWfRf83KmuCSNhg/ySY1ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSY0M+yaaZv7/vTYseYTKP\nXJF1+1kXf9RLCawX9+BSYwYuNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmODA59dG/3+JF6PTdog\n1rIHvwk4ONUgksY3dGWTbcC7gZ3TjiNpTEP34J8BbgGenXAWSSMbsvDBNcCxqtq7ynauTSYtmSF7\n8MuBa5P8AbgTuDLJV567kWuTSctn1cCr6hNVta2qLgSuA35UVR+YfDJJc/P34FJja7qiS1X9GPjx\nJJNIGp17cKkxA5caM3CpMQOXGjNwqTEDlxozcKkxA5cam2TpojNf8zxeefs5Uzz1/3jkzU+sy88B\nOHvX7nX7Wevt4l2LnkBTcA8uNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjU26JNssyuqPgH8\nC3imqrZPOZSkcazlo6pvq6q/TDaJpNF5iC41NjTwAn6QZG+SHVMOJGk8Qw/R31pVR5O8DLgnyaGq\n+snJG8zC3wGw9RVbRx5T0ukYtAevqqOzP48Bu4DLTrHNf5Yu2nLulnGnlHRahiw+uDXJOSduA+8A\nfjv1YJLmN+QQ/eXAriQntv9qVX1v0qkkjWLVwKvqMPD6dZhF0sj8NZnUmIFLjRm41JiBS40ZuNSY\ngUuNGbjUmIFLjU2ydNHxQ8+u65JCkk7NPbjUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFLjRm41Nig\nwJOcm+SuJIeSHEzylqkHkzS/oR9V/Szwvap6f5IzgbMnnEnSSFYNPMmLgCuADwJU1XHg+LRjSRrD\nkEP0i4DHgC8luT/Jztn10SUtuSGBnwG8Efh8VV0KPAXc+tyNkuxIsifJnn/y9MhjSjodQwI/Ahyp\nqt2z+3exEvx/OXnpos2cNeaMkk7TqoFX1Z+Ah5NcMnvoKuDApFNJGsXQs+gfAe6YnUE/DNw43UiS\nxjIo8KraD2yfeBZJI/OTbFJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm\n4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjqwae5JIk+0/6ejzJzesxnKT5rHrRxap6EHgDQJJNwFFg\n18RzSRrBWg/RrwJ+X1V/nGIYSeMael30E64DvnaqbyTZAewA2OLio9JSGLwHny16cC3wjVN936WL\npOWzlkP0dwL7qurPUw0jaVxrCfx6/s/huaTlNCjw2Xrgbwe+Ne04ksY0dG2yp4AXTzyLpJH5STap\nMQOXGjNwqTEDlxozcKkxA5caM3CpMQOXGktVjf+kyWPAWv9L6UuAv4w+zHLo+tp8XYvzqqp66Wob\nTRL46Uiyp6q2L3qOKXR9bb6u5echutSYgUuNLVPgX1j0ABPq+tp8XUtuad6DSxrfMu3BJY1sKQJP\ncnWSB5M8lOTWRc8zhiQXJLk3yYEkDyS5adEzjSnJpiT3J/nOomcZU5Jzk9yV5FCSg0nesuiZ5rHw\nQ/TZtdZ/x8oVY44A9wHXV9WBhQ42pyTnAedV1b4k5wB7gfdu9Nd1QpKPAduBF1bVNYueZyxJbgd+\nWlU7ZxcaPbuq/rbouU7XMuzBLwMeqqrDVXUcuBN4z4JnmltVPVpV+2a3nwAOAucvdqpxJNkGvBvY\nuehZxpTkRcAVwBcBqur4Ro4bliPw84GHT7p/hCYhnJDkQuBSYPdiJxnNZ4BbgGcXPcjILgIeA740\ne/uxc3Y9wg1rGQJvLckLgG8CN1fV44ueZ15JrgGOVdXeRc8ygTOANwKfr6pLgaeADX1OaBkCPwpc\ncNL9bbPHNrwkm1mJ+46q6nJF2suBa5P8gZW3U1cm+cpiRxrNEeBIVZ040rqLleA3rGUI/D7g1Uku\nmp3UuA749oJnmluSsPJe7mBVfXrR84ylqj5RVduq6kJW/q5+VFUfWPBYo6iqPwEPJ7lk9tBVwIY+\nKbrWtclGV1XPJPkw8H1gE3BbVT2w4LHGcDlwA/CbJPtnj32yqu5e4Exa3UeAO2Y7m8PAjQueZy4L\n/zWZpOkswyG6pIkYuNSYgUuNGbjUmIFLjRm41JiBS40ZuNTYvwGHEGYOU8JCjQAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f38a0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = Snake()\n",
    "img = s.reset()\n",
    "s.plot_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkzFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f38a940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, r, done = s.step(2)\n",
    "s.plot_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SnakeAgent:\n",
    "    \n",
    "    def __init__(self, model_name=\"baseline_agent\"):\n",
    "        \n",
    "        \"\"\"Class for training and evaluating DQN agent on Atari games\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        game_id: str\n",
    "            game identifier in gym environment, e.g. \"Pong\"\n",
    "        num_actions: int\n",
    "            number of actions the agent can take\n",
    "        model_name: str\n",
    "            name of the model\n",
    "        \"\"\"\n",
    "        \n",
    "        ############################ Game environment ############################\n",
    "        \n",
    "        self.train_env = Snake()\n",
    "        self.num_actions = 4\n",
    "            \n",
    "        self.path = \"snake_models\" + \"/\" + model_name\n",
    "        if not os.path.exists(self.path):\n",
    "            os.makedirs(self.path)\n",
    "        \n",
    "        ############################# Agent & Target #############################\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self.agent_net = QNetwork(self.num_actions, scope=\"agent\")\n",
    "        self.target_net = QNetwork(self.num_actions, scope=\"target\")\n",
    "        \n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        all_vars = tf.trainable_variables()\n",
    "        num_vars = len(all_vars) // 2\n",
    "        self.agent_vars = all_vars[:num_vars]\n",
    "        self.target_vars = all_vars[num_vars:]\n",
    "        \n",
    "    def set_parameters(self, \n",
    "                       replay_memory_size=50000,\n",
    "                       replay_start_size=10000,\n",
    "                       init_eps=1,\n",
    "                       final_eps=0.1,\n",
    "                       annealing_steps=100000,\n",
    "                       discount_factor=0.99,\n",
    "                       max_episode_length=2000):\n",
    "        \n",
    "        # create experience replay and fill it with random policy samples\n",
    "        self.rep_buffer = ReplayMemory(replay_memory_size)\n",
    "        frame_count = 0\n",
    "        while (frame_count < replay_start_size):\n",
    "            s = self.train_env.reset()\n",
    "            for time_step in range(max_episode_length):\n",
    "                a = np.random.randint(self.num_actions)\n",
    "                s_, r, end = self.train_env.step(a)\n",
    "                self.rep_buffer.push(s, a, np.sign(r), s_, end)\n",
    "                s = s_\n",
    "                frame_count += 1\n",
    "                if end:\n",
    "                    break\n",
    "                        \n",
    "        self.eps = init_eps\n",
    "        self.final_eps = final_eps\n",
    "        self.eps_drop = (init_eps - final_eps) / annealing_steps\n",
    "        self.gamma = discount_factor\n",
    "        self.max_ep_length = max_episode_length\n",
    "        \n",
    "    def train(self,\n",
    "              gpu_id=0,\n",
    "              batch_size=32,\n",
    "              agent_update_freq=4,\n",
    "              target_update_freq=5000,\n",
    "              tau=1,\n",
    "              max_num_episodes=100000,\n",
    "              max_num_epochs=50000,\n",
    "              performance_print_freq=100,\n",
    "              save_freq=10000):\n",
    "        \n",
    "        target_ops = self.update_target_graph(tau)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(self.init)\n",
    "            \n",
    "            train_rewards = []\n",
    "            frame_count = 0\n",
    "            episode_count = 0\n",
    "            num_epochs = 0\n",
    "            \n",
    "            while num_epochs < max_num_epochs:\n",
    "                \n",
    "                train_ep_reward = 0\n",
    "                \n",
    "                # reset the environment / start new game\n",
    "                s = self.train_env.reset()\n",
    "                for time_step in range(self.max_ep_length):\n",
    "                    \n",
    "                    # choose action e-greedily\n",
    "                    if np.random.rand(1) < self.eps:\n",
    "                        a = np.random.randint(self.num_actions)\n",
    "                    else:\n",
    "                        a = self.agent_net.get_q_argmax(sess, [s])\n",
    "                        \n",
    "                    # make step in the environment    \n",
    "                    s_, r, end = self.train_env.step(a)\n",
    "                    \n",
    "                    # save transition into experience replay\n",
    "                    self.rep_buffer.push(s, a, np.sign(r), s_, end)\n",
    "                    \n",
    "                    # update current state and statistics\n",
    "                    s = s_\n",
    "                    frame_count += 1\n",
    "                    train_ep_reward += r\n",
    "                    \n",
    "                    # reduce epsilon according to schedule\n",
    "                    if self.eps > self.final_eps:\n",
    "                        self.eps -= self.eps_drop\n",
    "                    \n",
    "                    # update network weights\n",
    "                    if frame_count % agent_update_freq == 0:\n",
    "                        \n",
    "                        batch = self.rep_buffer.get_batch(batch_size)\n",
    "                        \n",
    "                        # estimate right hand side of the Bellman equation\n",
    "                        max_actions = self.agent_net.get_q_argmax(sess, batch.s_)\n",
    "                        q_values = self.target_net.get_q_values(sess, batch.s_)\n",
    "                        double_q = q_values[np.arange(batch_size), max_actions]\n",
    "                        targets = batch.r + (self.gamma * double_q * batch.end)\n",
    "                        \n",
    "                        # update agent network\n",
    "                        self.agent_net.update(sess, batch.s, batch.a, targets)\n",
    "                        \n",
    "                        # update target network\n",
    "                        if tau == 1:\n",
    "                            if frame_count % target_update_freq == 0:\n",
    "                                self.update_target_weights(sess, target_ops)\n",
    "                        else: self.update_target_weights(sess, target_ops)\n",
    "                    \n",
    "                    # make checkpoints of network weights and save learning curve\n",
    "                    if frame_count % save_freq == 1:\n",
    "                        num_epochs += 1\n",
    "                        try:\n",
    "                            self.saver.save(sess, self.path+\"/model\", global_step=num_epochs)\n",
    "                            np.savez(self.path+\"/learning_curve.npz\", r=train_rewards)\n",
    "                        except:\n",
    "                            pass\n",
    "                    \n",
    "                    # if game is over, reset the environment\n",
    "                    if end: \n",
    "                        break\n",
    "                         \n",
    "                episode_count += 1\n",
    "                train_rewards.append(train_ep_reward)\n",
    "                \n",
    "                # print performance once in a while\n",
    "                if episode_count % performance_print_freq == 0:\n",
    "                    avg_reward = np.mean(train_rewards[-performance_print_freq:])\n",
    "                    print(\"Train info:\", frame_count, avg_reward, self.eps)  \n",
    "\n",
    "    def update_target_graph(self, tau):\n",
    "        op_holder = []\n",
    "        for agnt, trgt in zip(self.agent_vars, self.target_vars):\n",
    "            op = trgt.assign(agnt.value()*tau + (1 - tau)*trgt.value())\n",
    "            op_holder.append(op)\n",
    "        return op_holder\n",
    "\n",
    "    def update_target_weights(self, sess, op_holder):\n",
    "        for op in op_holder:\n",
    "            sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = SnakeAgent(model_name=\"baseline_dqn2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa.set_parameters(max_episode_length=1000, replay_memory_size=50000, replay_start_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train info: 784 -0.89 0.9929439999999712\n",
      "Train info: 1684 -0.87 0.9848439999999381\n",
      "Train info: 2582 -0.86 0.9767619999999051\n",
      "Train info: 3306 -0.9 0.9702459999998785\n",
      "Train info: 4222 -0.87 0.9620019999998448\n",
      "Train info: 5010 -0.88 0.9549099999998159\n",
      "Train info: 5865 -0.91 0.9472149999997844\n",
      "Train info: 6680 -0.91 0.9398799999997545\n",
      "Train info: 7557 -0.86 0.9319869999997222\n",
      "Train info: 8379 -0.91 0.924588999999692\n",
      "Train info: 9242 -0.91 0.9168219999996603\n",
      "Train info: 10096 -0.89 0.9091359999996289\n",
      "Train info: 11070 -0.89 0.9003699999995931\n",
      "Train info: 12036 -0.89 0.8916759999995576\n",
      "Train info: 12909 -0.92 0.8838189999995255\n",
      "Train info: 13679 -0.9 0.8768889999994972\n",
      "Train info: 14563 -0.92 0.8689329999994647\n",
      "Train info: 15411 -0.89 0.8613009999994335\n",
      "Train info: 16316 -0.86 0.8531559999994003\n",
      "Train info: 17079 -0.89 0.8462889999993722\n",
      "Train info: 17991 -0.83 0.8380809999993387\n",
      "Train info: 19030 -0.8 0.8287299999993005\n",
      "Train info: 19748 -0.91 0.8222679999992741\n",
      "Train info: 20525 -0.89 0.8152749999992456\n",
      "Train info: 21363 -0.92 0.8077329999992148\n",
      "Train info: 22173 -0.9 0.800442999999185\n",
      "Train info: 22948 -0.87 0.7934679999991565\n",
      "Train info: 23938 -0.9 0.7845579999991201\n",
      "Train info: 24843 -0.93 0.7764129999990869\n",
      "Train info: 25715 -0.83 0.7685649999990548\n",
      "Train info: 26628 -0.89 0.7603479999990213\n",
      "Train info: 27544 -0.9 0.7521039999989876\n",
      "Train info: 28414 -0.88 0.7442739999989556\n",
      "Train info: 29419 -0.88 0.7352289999989187\n",
      "Train info: 30431 -0.88 0.7261209999988815\n",
      "Train info: 31420 -0.84 0.7172199999988451\n",
      "Train info: 32509 -0.83 0.7074189999988051\n",
      "Train info: 33495 -0.87 0.6985449999987688\n",
      "Train info: 34466 -0.9 0.6898059999987332\n",
      "Train info: 35500 -0.91 0.6804999999986951\n",
      "Train info: 36611 -0.9 0.6705009999986543\n",
      "Train info: 37651 -0.9 0.6611409999986161\n",
      "Train info: 38681 -0.84 0.6518709999985782\n",
      "Train info: 39741 -0.86 0.6423309999985393\n",
      "Train info: 40764 -0.91 0.6331239999985017\n",
      "Train info: 41819 -0.88 0.6236289999984629\n",
      "Train info: 42910 -0.84 0.6138099999984228\n",
      "Train info: 44012 -0.9 0.6038919999983823\n",
      "Train info: 45008 -0.86 0.5949279999983457\n",
      "Train info: 45975 -0.93 0.5862249999983101\n",
      "Train info: 46982 -0.92 0.5771619999982731\n",
      "Train info: 48078 -0.9 0.5672979999982328\n",
      "Train info: 49148 -0.8 0.5576679999981935\n",
      "Train info: 50288 -0.87 0.5474079999981516\n",
      "Train info: 51433 -0.92 0.5371029999981095\n",
      "Train info: 52607 -0.77 0.5265369999980664\n",
      "Train info: 53564 -0.93 0.5179239999980312\n",
      "Train info: 54782 -0.85 0.5069619999979864\n",
      "Train info: 55955 -0.85 0.4964049999979655\n",
      "Train info: 57105 -0.88 0.48605499999798707\n",
      "Train info: 58092 -0.91 0.4771719999980056\n",
      "Train info: 59289 -0.92 0.46639899999802803\n",
      "Train info: 60515 -0.91 0.455364999998051\n",
      "Train info: 61885 -0.91 0.4430349999980767\n",
      "Train info: 63054 -0.89 0.43251399999809864\n",
      "Train info: 64221 -0.89 0.42201099999812053\n",
      "Train info: 65465 -0.9 0.41081499999814386\n",
      "Train info: 66719 -0.89 0.3995289999981674\n",
      "Train info: 68007 -0.87 0.38793699999819153\n",
      "Train info: 69275 -0.91 0.3765249999982153\n",
      "Train info: 70601 -0.92 0.3645909999982402\n",
      "Train info: 72078 -0.92 0.3512979999982679\n",
      "Train info: 73638 -0.86 0.33725799999829714\n",
      "Train info: 74993 -0.89 0.32506299999832255\n",
      "Train info: 76471 -0.87 0.3117609999983503\n",
      "Train info: 78054 -0.9 0.29751399999837996\n",
      "Train info: 79473 -0.88 0.2847429999984066\n",
      "Train info: 81118 -0.89 0.26993799999843743\n",
      "Train info: 82698 -0.87 0.25571799999846706\n",
      "Train info: 84347 -0.9 0.24087699999846984\n",
      "Train info: 86153 -0.88 0.2246229999984536\n",
      "Train info: 88519 -0.82 0.2033289999984323\n",
      "Train info: 90593 -0.82 0.18466299999841362\n",
      "Train info: 92834 -0.81 0.16449399999839345\n",
      "Train info: 95286 -0.88 0.14242599999837138\n",
      "Train info: 98289 -0.89 0.11539899999835916\n",
      "Train info: 102104 -0.84 0.0999999999983675\n",
      "Train info: 105004 -0.86 0.0999999999983675\n",
      "Train info: 109900 -0.92 0.0999999999983675\n",
      "Train info: 114285 -0.79 0.0999999999983675\n",
      "Train info: 121875 -0.77 0.0999999999983675\n",
      "Train info: 127847 -0.87 0.0999999999983675\n",
      "Train info: 136461 -0.76 0.0999999999983675\n",
      "Train info: 144038 -0.77 0.0999999999983675\n",
      "Train info: 149968 -0.78 0.0999999999983675\n",
      "Train info: 154791 -0.81 0.0999999999983675\n",
      "Train info: 161515 -0.84 0.0999999999983675\n",
      "Train info: 168239 -0.8 0.0999999999983675\n",
      "Train info: 175258 -0.8 0.0999999999983675\n",
      "Train info: 181626 -0.79 0.0999999999983675\n",
      "Train info: 189555 -0.83 0.0999999999983675\n",
      "Train info: 196958 -0.78 0.0999999999983675\n",
      "Train info: 204224 -0.74 0.0999999999983675\n",
      "Train info: 213073 -0.76 0.0999999999983675\n",
      "Train info: 221808 -0.79 0.0999999999983675\n",
      "Train info: 234188 -0.71 0.0999999999983675\n",
      "Train info: 245806 -0.73 0.0999999999983675\n",
      "Train info: 255326 -0.64 0.0999999999983675\n",
      "Train info: 262543 -0.7 0.0999999999983675\n",
      "Train info: 272554 -0.69 0.0999999999983675\n",
      "Train info: 281566 -0.64 0.0999999999983675\n",
      "Train info: 292497 -0.72 0.0999999999983675\n",
      "Train info: 305762 -0.55 0.0999999999983675\n",
      "Train info: 317131 -0.51 0.0999999999983675\n",
      "Train info: 328498 -0.45 0.0999999999983675\n",
      "Train info: 341522 -0.48 0.0999999999983675\n",
      "Train info: 350952 -0.56 0.0999999999983675\n",
      "Train info: 364116 -0.55 0.0999999999983675\n",
      "Train info: 375639 -0.5 0.0999999999983675\n",
      "Train info: 387887 -0.44 0.0999999999983675\n",
      "Train info: 397594 -0.59 0.0999999999983675\n",
      "Train info: 406703 -0.49 0.0999999999983675\n",
      "Train info: 417129 -0.28 0.0999999999983675\n",
      "Train info: 424124 -0.26 0.0999999999983675\n",
      "Train info: 433787 -0.38 0.0999999999983675\n",
      "Train info: 441746 -0.44 0.0999999999983675\n",
      "Train info: 449656 -0.42 0.0999999999983675\n",
      "Train info: 455675 -0.32 0.0999999999983675\n",
      "Train info: 465525 -0.33 0.0999999999983675\n",
      "Train info: 474544 -0.3 0.0999999999983675\n",
      "Train info: 485193 -0.25 0.0999999999983675\n",
      "Train info: 494487 -0.1 0.0999999999983675\n",
      "Train info: 503137 0.04 0.0999999999983675\n",
      "Train info: 510276 -0.06 0.0999999999983675\n",
      "Train info: 518145 -0.05 0.0999999999983675\n",
      "Train info: 524196 -0.17 0.0999999999983675\n",
      "Train info: 530722 -0.23 0.0999999999983675\n",
      "Train info: 537672 -0.09 0.0999999999983675\n",
      "Train info: 543789 0.07 0.0999999999983675\n",
      "Train info: 549746 0.13 0.0999999999983675\n",
      "Train info: 555984 0.27 0.0999999999983675\n",
      "Train info: 563296 0.48 0.0999999999983675\n",
      "Train info: 569822 0.15 0.0999999999983675\n",
      "Train info: 576107 0.21 0.0999999999983675\n",
      "Train info: 582431 0.31 0.0999999999983675\n",
      "Train info: 588836 0.18 0.0999999999983675\n",
      "Train info: 594491 0.15 0.0999999999983675\n",
      "Train info: 601995 0.21 0.0999999999983675\n",
      "Train info: 608717 0.42 0.0999999999983675\n",
      "Train info: 616347 0.34 0.0999999999983675\n",
      "Train info: 623276 0.24 0.0999999999983675\n",
      "Train info: 630088 0.22 0.0999999999983675\n",
      "Train info: 635975 0.07 0.0999999999983675\n",
      "Train info: 642592 0.13 0.0999999999983675\n",
      "Train info: 648576 0.43 0.0999999999983675\n",
      "Train info: 654068 0.22 0.0999999999983675\n",
      "Train info: 660176 0.17 0.0999999999983675\n",
      "Train info: 665947 0.38 0.0999999999983675\n",
      "Train info: 672151 0.36 0.0999999999983675\n",
      "Train info: 678226 0.61 0.0999999999983675\n",
      "Train info: 684453 0.26 0.0999999999983675\n",
      "Train info: 690807 0.49 0.0999999999983675\n",
      "Train info: 696987 0.48 0.0999999999983675\n",
      "Train info: 703575 0.35 0.0999999999983675\n",
      "Train info: 708401 0.4 0.0999999999983675\n",
      "Train info: 714104 0.47 0.0999999999983675\n",
      "Train info: 720581 0.46 0.0999999999983675\n",
      "Train info: 725642 0.54 0.0999999999983675\n",
      "Train info: 731167 0.2 0.0999999999983675\n",
      "Train info: 737496 0.32 0.0999999999983675\n",
      "Train info: 742921 0.41 0.0999999999983675\n",
      "Train info: 749102 0.59 0.0999999999983675\n",
      "Train info: 754266 0.66 0.0999999999983675\n",
      "Train info: 759845 0.76 0.0999999999983675\n",
      "Train info: 764961 0.76 0.0999999999983675\n",
      "Train info: 769200 0.71 0.0999999999983675\n",
      "Train info: 774116 0.73 0.0999999999983675\n",
      "Train info: 779108 0.5 0.0999999999983675\n",
      "Train info: 784390 0.86 0.0999999999983675\n",
      "Train info: 789603 0.79 0.0999999999983675\n",
      "Train info: 795023 0.74 0.0999999999983675\n",
      "Train info: 799608 0.64 0.0999999999983675\n",
      "Train info: 804652 0.86 0.0999999999983675\n",
      "Train info: 810159 0.63 0.0999999999983675\n",
      "Train info: 815660 0.87 0.0999999999983675\n",
      "Train info: 821058 0.74 0.0999999999983675\n",
      "Train info: 826174 0.62 0.0999999999983675\n",
      "Train info: 830963 0.48 0.0999999999983675\n",
      "Train info: 836685 1.08 0.0999999999983675\n",
      "Train info: 842615 1.03 0.0999999999983675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train info: 847722 0.48 0.0999999999983675\n",
      "Train info: 853016 0.71 0.0999999999983675\n",
      "Train info: 857213 0.76 0.0999999999983675\n",
      "Train info: 862352 0.84 0.0999999999983675\n",
      "Train info: 867052 0.93 0.0999999999983675\n",
      "Train info: 871372 0.66 0.0999999999983675\n",
      "Train info: 875508 0.93 0.0999999999983675\n",
      "Train info: 880253 0.82 0.0999999999983675\n",
      "Train info: 884790 0.81 0.0999999999983675\n",
      "Train info: 889478 0.84 0.0999999999983675\n",
      "Train info: 894271 0.94 0.0999999999983675\n",
      "Train info: 898465 0.87 0.0999999999983675\n",
      "Train info: 903860 1.51 0.0999999999983675\n",
      "Train info: 909075 1.03 0.0999999999983675\n",
      "Train info: 913117 0.86 0.0999999999983675\n",
      "Train info: 917808 1.24 0.0999999999983675\n",
      "Train info: 922223 1.15 0.0999999999983675\n",
      "Train info: 927181 1.42 0.0999999999983675\n",
      "Train info: 931430 1.03 0.0999999999983675\n",
      "Train info: 935565 1.11 0.0999999999983675\n",
      "Train info: 940277 1.19 0.0999999999983675\n",
      "Train info: 945005 1.09 0.0999999999983675\n",
      "Train info: 949876 1.33 0.0999999999983675\n",
      "Train info: 954527 1.3 0.0999999999983675\n",
      "Train info: 959698 1.37 0.0999999999983675\n",
      "Train info: 963590 1.06 0.0999999999983675\n",
      "Train info: 969259 1.64 0.0999999999983675\n",
      "Train info: 973305 0.96 0.0999999999983675\n",
      "Train info: 977467 1.31 0.0999999999983675\n",
      "Train info: 981301 1.09 0.0999999999983675\n",
      "Train info: 986620 1.28 0.0999999999983675\n",
      "Train info: 991502 1.33 0.0999999999983675\n",
      "Train info: 996462 1.3 0.0999999999983675\n",
      "Train info: 1001548 1.59 0.0999999999983675\n",
      "Train info: 1005757 1.11 0.0999999999983675\n",
      "Train info: 1010388 1.34 0.0999999999983675\n",
      "Train info: 1015309 1.53 0.0999999999983675\n",
      "Train info: 1019591 1.41 0.0999999999983675\n",
      "Train info: 1023597 1.35 0.0999999999983675\n",
      "Train info: 1028292 1.78 0.0999999999983675\n",
      "Train info: 1032809 1.38 0.0999999999983675\n",
      "Train info: 1038270 2.31 0.0999999999983675\n",
      "Train info: 1042385 1.38 0.0999999999983675\n",
      "Train info: 1046815 1.7 0.0999999999983675\n",
      "Train info: 1051027 1.56 0.0999999999983675\n",
      "Train info: 1055240 1.39 0.0999999999983675\n",
      "Train info: 1060299 1.92 0.0999999999983675\n",
      "Train info: 1065246 1.61 0.0999999999983675\n",
      "Train info: 1070147 1.95 0.0999999999983675\n",
      "Train info: 1075281 2.04 0.0999999999983675\n",
      "Train info: 1080159 1.55 0.0999999999983675\n",
      "Train info: 1085064 1.91 0.0999999999983675\n",
      "Train info: 1089829 1.85 0.0999999999983675\n",
      "Train info: 1093808 1.41 0.0999999999983675\n",
      "Train info: 1099003 2.0 0.0999999999983675\n",
      "Train info: 1103458 1.83 0.0999999999983675\n",
      "Train info: 1108036 1.87 0.0999999999983675\n",
      "Train info: 1113184 1.87 0.0999999999983675\n",
      "Train info: 1118051 1.98 0.0999999999983675\n",
      "Train info: 1122993 2.05 0.0999999999983675\n",
      "Train info: 1127165 1.55 0.0999999999983675\n",
      "Train info: 1131479 1.72 0.0999999999983675\n",
      "Train info: 1135969 1.8 0.0999999999983675\n",
      "Train info: 1140591 1.87 0.0999999999983675\n",
      "Train info: 1146629 2.58 0.0999999999983675\n",
      "Train info: 1151087 1.96 0.0999999999983675\n",
      "Train info: 1156045 1.85 0.0999999999983675\n",
      "Train info: 1161505 2.09 0.0999999999983675\n",
      "Train info: 1165837 1.42 0.0999999999983675\n",
      "Train info: 1170117 1.68 0.0999999999983675\n",
      "Train info: 1174616 1.94 0.0999999999983675\n",
      "Train info: 1179399 2.18 0.0999999999983675\n",
      "Train info: 1183595 1.55 0.0999999999983675\n",
      "Train info: 1188369 1.84 0.0999999999983675\n",
      "Train info: 1192279 1.37 0.0999999999983675\n",
      "Train info: 1196794 1.93 0.0999999999983675\n",
      "Train info: 1201581 2.03 0.0999999999983675\n",
      "Train info: 1206271 1.8 0.0999999999983675\n",
      "Train info: 1210330 1.79 0.0999999999983675\n",
      "Train info: 1214829 1.83 0.0999999999983675\n",
      "Train info: 1219187 1.88 0.0999999999983675\n",
      "Train info: 1224256 2.18 0.0999999999983675\n",
      "Train info: 1229704 2.52 0.0999999999983675\n",
      "Train info: 1234889 2.5 0.0999999999983675\n",
      "Train info: 1239512 2.05 0.0999999999983675\n",
      "Train info: 1244523 2.01 0.0999999999983675\n",
      "Train info: 1249297 1.9 0.0999999999983675\n",
      "Train info: 1253751 2.07 0.0999999999983675\n",
      "Train info: 1257808 1.6 0.0999999999983675\n",
      "Train info: 1262774 2.1 0.0999999999983675\n",
      "Train info: 1268387 2.33 0.0999999999983675\n",
      "Train info: 1273121 1.99 0.0999999999983675\n",
      "Train info: 1278124 1.8 0.0999999999983675\n",
      "Train info: 1282004 1.61 0.0999999999983675\n",
      "Train info: 1287296 2.28 0.0999999999983675\n",
      "Train info: 1293267 2.48 0.0999999999983675\n",
      "Train info: 1298106 1.95 0.0999999999983675\n",
      "Train info: 1303828 2.67 0.0999999999983675\n",
      "Train info: 1308436 2.01 0.0999999999983675\n",
      "Train info: 1313401 2.42 0.0999999999983675\n",
      "Train info: 1318241 2.44 0.0999999999983675\n",
      "Train info: 1323281 2.07 0.0999999999983675\n",
      "Train info: 1327974 1.96 0.0999999999983675\n",
      "Train info: 1332031 1.69 0.0999999999983675\n",
      "Train info: 1336533 1.96 0.0999999999983675\n",
      "Train info: 1340656 1.47 0.0999999999983675\n",
      "Train info: 1345676 2.2 0.0999999999983675\n",
      "Train info: 1350028 2.06 0.0999999999983675\n",
      "Train info: 1354586 2.19 0.0999999999983675\n",
      "Train info: 1359000 1.92 0.0999999999983675\n",
      "Train info: 1363704 2.22 0.0999999999983675\n",
      "Train info: 1368291 1.89 0.0999999999983675\n",
      "Train info: 1373508 2.35 0.0999999999983675\n",
      "Train info: 1378411 2.05 0.0999999999983675\n",
      "Train info: 1383794 2.44 0.0999999999983675\n",
      "Train info: 1388810 2.26 0.0999999999983675\n",
      "Train info: 1393811 2.12 0.0999999999983675\n",
      "Train info: 1398485 2.1 0.0999999999983675\n",
      "Train info: 1403686 2.52 0.0999999999983675\n",
      "Train info: 1408853 2.3 0.0999999999983675\n",
      "Train info: 1413379 2.31 0.0999999999983675\n",
      "Train info: 1418384 2.0 0.0999999999983675\n",
      "Train info: 1422783 2.28 0.0999999999983675\n",
      "Train info: 1427296 2.13 0.0999999999983675\n",
      "Train info: 1431506 1.85 0.0999999999983675\n",
      "Train info: 1436943 2.51 0.0999999999983675\n",
      "Train info: 1442558 2.39 0.0999999999983675\n",
      "Train info: 1447549 2.15 0.0999999999983675\n",
      "Train info: 1452503 2.22 0.0999999999983675\n",
      "Train info: 1457920 2.36 0.0999999999983675\n",
      "Train info: 1463221 2.32 0.0999999999983675\n",
      "Train info: 1467963 2.14 0.0999999999983675\n",
      "Train info: 1472444 1.83 0.0999999999983675\n",
      "Train info: 1477373 2.04 0.0999999999983675\n",
      "Train info: 1482294 2.47 0.0999999999983675\n",
      "Train info: 1486981 2.12 0.0999999999983675\n",
      "Train info: 1493056 2.54 0.0999999999983675\n",
      "Train info: 1498627 2.56 0.0999999999983675\n",
      "Train info: 1503677 2.14 0.0999999999983675\n",
      "Train info: 1509371 2.63 0.0999999999983675\n",
      "Train info: 1514133 1.91 0.0999999999983675\n",
      "Train info: 1519305 2.5 0.0999999999983675\n",
      "Train info: 1523986 1.81 0.0999999999983675\n",
      "Train info: 1529318 1.96 0.0999999999983675\n",
      "Train info: 1534522 2.35 0.0999999999983675\n",
      "Train info: 1539067 1.91 0.0999999999983675\n",
      "Train info: 1544064 2.04 0.0999999999983675\n",
      "Train info: 1549274 2.27 0.0999999999983675\n",
      "Train info: 1554290 2.24 0.0999999999983675\n",
      "Train info: 1559676 2.37 0.0999999999983675\n",
      "Train info: 1564996 2.28 0.0999999999983675\n",
      "Train info: 1569592 1.92 0.0999999999983675\n",
      "Train info: 1574742 2.29 0.0999999999983675\n",
      "Train info: 1579687 2.12 0.0999999999983675\n",
      "Train info: 1584250 2.05 0.0999999999983675\n",
      "Train info: 1589612 2.05 0.0999999999983675\n",
      "Train info: 1594437 2.14 0.0999999999983675\n",
      "Train info: 1599580 2.38 0.0999999999983675\n",
      "Train info: 1604920 2.28 0.0999999999983675\n",
      "Train info: 1609692 2.04 0.0999999999983675\n",
      "Train info: 1615534 2.75 0.0999999999983675\n",
      "Train info: 1620166 2.17 0.0999999999983675\n",
      "Train info: 1625657 2.34 0.0999999999983675\n",
      "Train info: 1630942 2.09 0.0999999999983675\n",
      "Train info: 1635408 1.89 0.0999999999983675\n",
      "Train info: 1640657 2.32 0.0999999999983675\n",
      "Train info: 1645605 2.3 0.0999999999983675\n",
      "Train info: 1650647 2.19 0.0999999999983675\n",
      "Train info: 1655762 2.43 0.0999999999983675\n",
      "Train info: 1660601 1.93 0.0999999999983675\n",
      "Train info: 1666294 2.34 0.0999999999983675\n",
      "Train info: 1670934 1.86 0.0999999999983675\n",
      "Train info: 1675871 2.02 0.0999999999983675\n",
      "Train info: 1682030 2.83 0.0999999999983675\n",
      "Train info: 1687257 2.05 0.0999999999983675\n",
      "Train info: 1692750 2.76 0.0999999999983675\n",
      "Train info: 1698413 2.56 0.0999999999983675\n",
      "Train info: 1703499 2.37 0.0999999999983675\n",
      "Train info: 1708776 2.75 0.0999999999983675\n",
      "Train info: 1713701 2.29 0.0999999999983675\n",
      "Train info: 1718375 1.99 0.0999999999983675\n",
      "Train info: 1722951 2.31 0.0999999999983675\n",
      "Train info: 1728036 2.29 0.0999999999983675\n",
      "Train info: 1732596 2.25 0.0999999999983675\n",
      "Train info: 1737811 2.5 0.0999999999983675\n",
      "Train info: 1743001 2.68 0.0999999999983675\n",
      "Train info: 1748569 2.87 0.0999999999983675\n",
      "Train info: 1753658 2.59 0.0999999999983675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train info: 1758749 2.62 0.0999999999983675\n",
      "Train info: 1763349 2.12 0.0999999999983675\n",
      "Train info: 1768343 2.21 0.0999999999983675\n",
      "Train info: 1772766 2.17 0.0999999999983675\n",
      "Train info: 1777530 2.23 0.0999999999983675\n",
      "Train info: 1782436 2.35 0.0999999999983675\n",
      "Train info: 1788224 2.51 0.0999999999983675\n",
      "Train info: 1793560 2.84 0.0999999999983675\n",
      "Train info: 1799146 2.51 0.0999999999983675\n",
      "Train info: 1803942 2.18 0.0999999999983675\n",
      "Train info: 1809284 2.51 0.0999999999983675\n",
      "Train info: 1814122 2.46 0.0999999999983675\n",
      "Train info: 1818895 2.21 0.0999999999983675\n",
      "Train info: 1824005 2.46 0.0999999999983675\n",
      "Train info: 1829289 2.68 0.0999999999983675\n",
      "Train info: 1834774 2.69 0.0999999999983675\n",
      "Train info: 1839741 2.1 0.0999999999983675\n",
      "Train info: 1845008 2.52 0.0999999999983675\n",
      "Train info: 1849671 2.03 0.0999999999983675\n",
      "Train info: 1855230 2.64 0.0999999999983675\n",
      "Train info: 1860776 2.51 0.0999999999983675\n",
      "Train info: 1865758 2.17 0.0999999999983675\n",
      "Train info: 1870867 2.32 0.0999999999983675\n",
      "Train info: 1877127 2.59 0.0999999999983675\n",
      "Train info: 1882784 2.43 0.0999999999983675\n",
      "Train info: 1887824 2.44 0.0999999999983675\n",
      "Train info: 1892409 2.08 0.0999999999983675\n",
      "Train info: 1897074 2.16 0.0999999999983675\n",
      "Train info: 1902188 2.59 0.0999999999983675\n",
      "Train info: 1906772 2.16 0.0999999999983675\n",
      "Train info: 1911932 1.98 0.0999999999983675\n",
      "Train info: 1917084 2.24 0.0999999999983675\n",
      "Train info: 1921743 2.0 0.0999999999983675\n",
      "Train info: 1926999 2.61 0.0999999999983675\n",
      "Train info: 1932052 2.18 0.0999999999983675\n",
      "Train info: 1937097 2.28 0.0999999999983675\n",
      "Train info: 1942255 2.39 0.0999999999983675\n",
      "Train info: 1947455 2.45 0.0999999999983675\n",
      "Train info: 1952904 2.3 0.0999999999983675\n",
      "Train info: 1958447 2.46 0.0999999999983675\n",
      "Train info: 1963063 1.82 0.0999999999983675\n",
      "Train info: 1967532 2.07 0.0999999999983675\n",
      "Train info: 1972519 2.11 0.0999999999983675\n",
      "Train info: 1978050 2.45 0.0999999999983675\n",
      "Train info: 1982479 2.21 0.0999999999983675\n",
      "Train info: 1987962 2.75 0.0999999999983675\n",
      "Train info: 1992876 2.48 0.0999999999983675\n",
      "Train info: 1997752 2.47 0.0999999999983675\n",
      "Train info: 2002700 2.45 0.0999999999983675\n",
      "Train info: 2007576 2.5 0.0999999999983675\n",
      "Train info: 2012497 2.65 0.0999999999983675\n",
      "Train info: 2017762 2.68 0.0999999999983675\n",
      "Train info: 2022825 2.52 0.0999999999983675\n",
      "Train info: 2027778 2.27 0.0999999999983675\n",
      "Train info: 2032523 2.19 0.0999999999983675\n",
      "Train info: 2037549 2.46 0.0999999999983675\n",
      "Train info: 2042755 2.35 0.0999999999983675\n",
      "Train info: 2047519 2.32 0.0999999999983675\n",
      "Train info: 2052711 2.65 0.0999999999983675\n",
      "Train info: 2057280 2.18 0.0999999999983675\n",
      "Train info: 2062457 2.64 0.0999999999983675\n",
      "Train info: 2067513 2.46 0.0999999999983675\n",
      "Train info: 2073222 2.99 0.0999999999983675\n",
      "Train info: 2078609 2.9 0.0999999999983675\n",
      "Train info: 2084181 2.71 0.0999999999983675\n",
      "Train info: 2089968 2.88 0.0999999999983675\n",
      "Train info: 2095311 2.76 0.0999999999983675\n",
      "Train info: 2100042 2.5 0.0999999999983675\n",
      "Train info: 2104850 2.35 0.0999999999983675\n",
      "Train info: 2110106 2.5 0.0999999999983675\n",
      "Train info: 2116041 3.19 0.0999999999983675\n",
      "Train info: 2121238 2.5 0.0999999999983675\n",
      "Train info: 2126646 2.78 0.0999999999983675\n",
      "Train info: 2131269 2.52 0.0999999999983675\n",
      "Train info: 2136363 2.59 0.0999999999983675\n",
      "Train info: 2141378 2.36 0.0999999999983675\n",
      "Train info: 2146180 2.36 0.0999999999983675\n",
      "Train info: 2150634 2.09 0.0999999999983675\n",
      "Train info: 2155733 2.47 0.0999999999983675\n",
      "Train info: 2160687 2.76 0.0999999999983675\n",
      "Train info: 2165223 2.38 0.0999999999983675\n",
      "Train info: 2169774 2.07 0.0999999999983675\n",
      "Train info: 2174766 2.65 0.0999999999983675\n",
      "Train info: 2179973 2.66 0.0999999999983675\n",
      "Train info: 2184835 2.6 0.0999999999983675\n",
      "Train info: 2189630 2.15 0.0999999999983675\n",
      "Train info: 2194006 2.21 0.0999999999983675\n",
      "Train info: 2198896 2.65 0.0999999999983675\n",
      "Train info: 2203985 2.44 0.0999999999983675\n",
      "Train info: 2209097 2.54 0.0999999999983675\n",
      "Train info: 2214513 2.74 0.0999999999983675\n",
      "Train info: 2219382 2.54 0.0999999999983675\n",
      "Train info: 2224395 2.36 0.0999999999983675\n",
      "Train info: 2229888 2.91 0.0999999999983675\n",
      "Train info: 2235024 2.53 0.0999999999983675\n",
      "Train info: 2240017 2.75 0.0999999999983675\n",
      "Train info: 2246072 2.95 0.0999999999983675\n",
      "Train info: 2252076 2.99 0.0999999999983675\n",
      "Train info: 2258291 3.08 0.0999999999983675\n",
      "Train info: 2263032 2.25 0.0999999999983675\n",
      "Train info: 2267918 2.6 0.0999999999983675\n",
      "Train info: 2272593 2.37 0.0999999999983675\n",
      "Train info: 2277907 2.77 0.0999999999983675\n",
      "Train info: 2283296 2.94 0.0999999999983675\n",
      "Train info: 2288435 2.76 0.0999999999983675\n",
      "Train info: 2293795 2.79 0.0999999999983675\n",
      "Train info: 2298466 2.48 0.0999999999983675\n",
      "Train info: 2303945 2.9 0.0999999999983675\n",
      "Train info: 2308813 2.43 0.0999999999983675\n",
      "Train info: 2314129 2.79 0.0999999999983675\n",
      "Train info: 2319895 2.86 0.0999999999983675\n",
      "Train info: 2325067 2.61 0.0999999999983675\n",
      "Train info: 2330020 2.55 0.0999999999983675\n",
      "Train info: 2334775 2.48 0.0999999999983675\n",
      "Train info: 2339297 2.4 0.0999999999983675\n",
      "Train info: 2344215 2.5 0.0999999999983675\n",
      "Train info: 2350312 3.28 0.0999999999983675\n",
      "Train info: 2354978 2.6 0.0999999999983675\n",
      "Train info: 2360434 3.01 0.0999999999983675\n",
      "Train info: 2365154 2.61 0.0999999999983675\n",
      "Train info: 2370229 2.42 0.0999999999983675\n",
      "Train info: 2375849 2.97 0.0999999999983675\n",
      "Train info: 2380707 2.66 0.0999999999983675\n",
      "Train info: 2385881 2.62 0.0999999999983675\n",
      "Train info: 2390695 2.5 0.0999999999983675\n",
      "Train info: 2395328 2.68 0.0999999999983675\n",
      "Train info: 2400133 2.29 0.0999999999983675\n",
      "Train info: 2405539 2.84 0.0999999999983675\n",
      "Train info: 2411357 3.27 0.0999999999983675\n",
      "Train info: 2416154 2.71 0.0999999999983675\n",
      "Train info: 2421577 2.88 0.0999999999983675\n",
      "Train info: 2426146 2.25 0.0999999999983675\n",
      "Train info: 2431112 2.43 0.0999999999983675\n",
      "Train info: 2436082 2.74 0.0999999999983675\n",
      "Train info: 2441140 2.92 0.0999999999983675\n",
      "Train info: 2446217 2.89 0.0999999999983675\n",
      "Train info: 2450339 2.34 0.0999999999983675\n",
      "Train info: 2455004 2.6 0.0999999999983675\n",
      "Train info: 2459780 2.8 0.0999999999983675\n",
      "Train info: 2465099 3.07 0.0999999999983675\n",
      "Train info: 2470031 2.61 0.0999999999983675\n",
      "Train info: 2475407 2.89 0.0999999999983675\n",
      "Train info: 2480532 2.87 0.0999999999983675\n",
      "Train info: 2485248 2.94 0.0999999999983675\n",
      "Train info: 2490270 2.5 0.0999999999983675\n",
      "Train info: 2494754 2.28 0.0999999999983675\n",
      "Train info: 2499289 2.33 0.0999999999983675\n",
      "Train info: 2504266 3.12 0.0999999999983675\n",
      "Train info: 2509404 3.13 0.0999999999983675\n",
      "Train info: 2514027 2.83 0.0999999999983675\n",
      "Train info: 2518882 2.67 0.0999999999983675\n",
      "Train info: 2524211 2.99 0.0999999999983675\n",
      "Train info: 2529503 2.86 0.0999999999983675\n",
      "Train info: 2534873 2.93 0.0999999999983675\n",
      "Train info: 2539646 2.79 0.0999999999983675\n",
      "Train info: 2545529 3.5 0.0999999999983675\n",
      "Train info: 2550363 2.51 0.0999999999983675\n",
      "Train info: 2555242 2.44 0.0999999999983675\n",
      "Train info: 2559740 2.5 0.0999999999983675\n",
      "Train info: 2564187 2.26 0.0999999999983675\n",
      "Train info: 2568922 2.51 0.0999999999983675\n",
      "Train info: 2573919 2.6 0.0999999999983675\n",
      "Train info: 2579581 3.16 0.0999999999983675\n",
      "Train info: 2584535 2.9 0.0999999999983675\n",
      "Train info: 2589431 2.84 0.0999999999983675\n",
      "Train info: 2594578 2.77 0.0999999999983675\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e6d96915fc51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-dbcc2d52c21e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gpu_id, batch_size, agent_update_freq, target_update_freq, tau, max_num_episodes, max_num_epochs, performance_print_freq, save_freq)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0;31m# update agent network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;31m# update target network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/projects/snake_research/methods.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, sess, states, actions, targets)\u001b[0m\n\u001b[1;32m    100\u001b[0m                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_actions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                      self.targets:targets}\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aa.train(gpu_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "agent_net = QNetwork(4, scope=\"agent\")\n",
    "saver = tf.train.Saver()\n",
    "env = Snake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f38a080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f38a080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"snake_models/baseline_dqn2/model-260\")\n",
    "    s = env.reset()\n",
    "    for i in range(20):\n",
    "        a = agent_net.get_q_argmax(sess, [s])[0]\n",
    "        s, r, done = env.step(a)\n",
    "        \n",
    "        \n",
    "        env.plot_state()\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        time.sleep(0.01)\n",
    "        \n",
    "        if done: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
