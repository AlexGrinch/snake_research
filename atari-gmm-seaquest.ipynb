{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/tf/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from PIL import Image\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_agents import *\n",
    "\n",
    "from atari_wrappers import wrap_deepmind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "game_id = \"SeaquestNoFrameskip-v4\"\n",
    "env = wrap_deepmind(gym.make(game_id), clip_rewards=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = GMMDQNAgent(env=env, num_actions=16, convs=[[32, 8, 4], [64, 4, 2], [64, 3, 1]], \n",
    "                 fully_connected=[512], state_shape=[84, 84, 4], save_path=\"atari_models/seaquest\", model_name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: <class 'atari_wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "aa.set_parameters(max_episode_length=5000, replay_memory_size=100000, replay_start_size=10000,\n",
    "                  discount_factor=0.999, final_eps=0.01, annealing_steps=300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame count: 937\n",
      "average reward: 4.0\n",
      "epsilon: 0.997\n",
      "average lifetime: 93.7\n",
      "-------------------------------\n",
      "frame count: 1950\n",
      "average reward: 8.0\n",
      "epsilon: 0.994\n",
      "average lifetime: 101.3\n",
      "-------------------------------\n",
      "frame count: 3201\n",
      "average reward: 4.0\n",
      "epsilon: 0.989\n",
      "average lifetime: 125.1\n",
      "-------------------------------\n",
      "frame count: 4294\n",
      "average reward: 0.0\n",
      "epsilon: 0.986\n",
      "average lifetime: 109.3\n",
      "-------------------------------\n",
      "frame count: 5404\n",
      "average reward: 10.0\n",
      "epsilon: 0.982\n",
      "average lifetime: 111.0\n",
      "-------------------------------\n",
      "frame count: 6320\n",
      "average reward: 4.0\n",
      "epsilon: 0.979\n",
      "average lifetime: 91.6\n",
      "-------------------------------\n",
      "frame count: 7244\n",
      "average reward: 4.0\n",
      "epsilon: 0.976\n",
      "average lifetime: 92.4\n",
      "-------------------------------\n",
      "frame count: 8458\n",
      "average reward: 8.0\n",
      "epsilon: 0.972\n",
      "average lifetime: 121.4\n",
      "-------------------------------\n",
      "frame count: 9650\n",
      "average reward: 10.0\n",
      "epsilon: 0.968\n",
      "average lifetime: 119.2\n",
      "-------------------------------\n",
      "frame count: 10652\n",
      "average reward: 6.0\n",
      "epsilon: 0.965\n",
      "average lifetime: 100.2\n",
      "-------------------------------\n",
      "frame count: 11671\n",
      "average reward: 6.0\n",
      "epsilon: 0.961\n",
      "average lifetime: 101.9\n",
      "-------------------------------\n",
      "frame count: 12812\n",
      "average reward: 12.0\n",
      "epsilon: 0.958\n",
      "average lifetime: 114.1\n",
      "-------------------------------\n",
      "frame count: 13776\n",
      "average reward: 2.0\n",
      "epsilon: 0.955\n",
      "average lifetime: 96.4\n",
      "-------------------------------\n",
      "frame count: 14841\n",
      "average reward: 12.0\n",
      "epsilon: 0.951\n",
      "average lifetime: 106.5\n",
      "-------------------------------\n",
      "frame count: 15688\n",
      "average reward: 0.0\n",
      "epsilon: 0.948\n",
      "average lifetime: 84.7\n",
      "-------------------------------\n",
      "frame count: 16788\n",
      "average reward: 10.0\n",
      "epsilon: 0.945\n",
      "average lifetime: 110.0\n",
      "-------------------------------\n",
      "frame count: 17861\n",
      "average reward: 6.0\n",
      "epsilon: 0.941\n",
      "average lifetime: 107.3\n",
      "-------------------------------\n",
      "frame count: 18848\n",
      "average reward: 6.0\n",
      "epsilon: 0.938\n",
      "average lifetime: 98.7\n",
      "-------------------------------\n",
      "frame count: 20031\n",
      "average reward: 8.0\n",
      "epsilon: 0.934\n",
      "average lifetime: 118.3\n",
      "-------------------------------\n",
      "frame count: 21181\n",
      "average reward: 14.0\n",
      "epsilon: 0.93\n",
      "average lifetime: 115.0\n",
      "-------------------------------\n",
      "frame count: 22067\n",
      "average reward: 2.0\n",
      "epsilon: 0.927\n",
      "average lifetime: 88.6\n",
      "-------------------------------\n",
      "frame count: 23025\n",
      "average reward: 2.0\n",
      "epsilon: 0.924\n",
      "average lifetime: 95.8\n",
      "-------------------------------\n",
      "frame count: 24127\n",
      "average reward: 14.0\n",
      "epsilon: 0.92\n",
      "average lifetime: 110.2\n",
      "-------------------------------\n",
      "frame count: 25127\n",
      "average reward: 10.0\n",
      "epsilon: 0.917\n",
      "average lifetime: 100.0\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "aa.train(gpu_id=5, exploration=\"e-greedy\", save_freq=1000000, max_num_epochs=1000, tau=1e-3, performance_print_freq=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
